{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ion Switching",
      "provenance": [],
      "collapsed_sections": [
        "WrWKKZ9Xl-Re",
        "1_QIr0q6mGBw",
        "Q75NF6xTMheC",
        "7jwFLQA2q9m7",
        "5ITZw2VjqVxF",
        "1WCTNKTuxk24",
        "HUs_TmgFD4m7",
        "fv-ciIzddW21",
        "kfkd63aag1x4",
        "iJv1P2g2RNPw",
        "TAtjkDzpyupX",
        "J8DCrNUkU0uY",
        "suVlLZNZAiZE",
        "rn3bDnsFBz2W",
        "MwW365uZDxvK",
        "HqnledmPB4tv"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7182aa4d3c474a5aa0fb76674eb485ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c499188295e848d9b341293ee29eb752",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cfeb70ac13fa47698aff36ff946d9cb6",
              "IPY_MODEL_8558a57d589e4c639f8c62a25d51d90d"
            ]
          }
        },
        "c499188295e848d9b341293ee29eb752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfeb70ac13fa47698aff36ff946d9cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c9ead65052d4080a4981ab3d4ec44d6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cc6a0bd8e1a455b8369bd3fd3091993"
          }
        },
        "8558a57d589e4c639f8c62a25d51d90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6acb4ff1c980477aaa390f60f1e62ebb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:20&lt;00:00,  4.59s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a74748419cb430a966be0d7493c8f64"
          }
        },
        "5c9ead65052d4080a4981ab3d4ec44d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cc6a0bd8e1a455b8369bd3fd3091993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6acb4ff1c980477aaa390f60f1e62ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a74748419cb430a966be0d7493c8f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c37ec8bb7ce4432a4703307524af8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77e8479da0f644a9b164752ae4477b76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0be9ca6013e64feb8dba42d3558f89c3",
              "IPY_MODEL_001d459adfa5465ea96204823b3b3c8a"
            ]
          }
        },
        "77e8479da0f644a9b164752ae4477b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0be9ca6013e64feb8dba42d3558f89c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da97d871bf694286bc816ccc899c15c7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5a1e9fbaee84df59bbbf5d55af17373"
          }
        },
        "001d459adfa5465ea96204823b3b3c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d13b0814e8b45ae85cfae2f8d6d378d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:09&lt;00:00,  1.99s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1fe526fd55147babc4f6db7179f31f5"
          }
        },
        "da97d871bf694286bc816ccc899c15c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5a1e9fbaee84df59bbbf5d55af17373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d13b0814e8b45ae85cfae2f8d6d378d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1fe526fd55147babc4f6db7179f31f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX2D-zkZey6g",
        "colab_type": "text"
      },
      "source": [
        "# Checking NVIDIA Driver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FxHF_YZWveQ",
        "colab_type": "text"
      },
      "source": [
        "Should be NVIDIA TESLA P100 or TESLA P4 so that we can complete training and prediction in one hour\n",
        "if TESLA K80 is shown then deep learning model will take 10 hours just to finish training  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KugXkhg5Kzkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSzABZZskQKH",
        "colab_type": "text"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_EIYHDkzlH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import random\n",
        "import sklearn\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "from tqdm import tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from IPython.display import display,HTML\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import losses, models, optimizers\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM \n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from sklearn.model_selection import KFold, train_test_split, GroupKFold\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler, Callback\n",
        "from tensorflow.keras.layers import Dense, Dropout, Add, Conv1D, Flatten,BatchNormalization, Activation, AveragePooling1D,Bidirectional, Multiply,SpatialDropout1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D, Lambda,Input, Concatenate, UpSampling1D, Multiply,MaxPooling1D,LSTM,TimeDistributed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzkfbqoSk0TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows',None)\n",
        "pd.set_option('display.max_columns',None)\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['figure.figsize'] = (20,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWYXEdehkaRm",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDv-7gpaDedD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature Engineering Function\n",
        "def get_features(df : pd.DataFrame,\n",
        "                diff = False,\n",
        "                shift_sizes = [1, 2, 3, 4, 5],\n",
        "                add_pct_change = False,\n",
        "                add_pct_change_lag = False) -> pd.DataFrame:\n",
        "\n",
        "\n",
        "    df['group'] = df.groupby(df.index//4000).agg('ngroup').astype(np.int32)\n",
        "\n",
        "    for shift_size in tqdm_notebook(shift_sizes,leave=False):    \n",
        "        df['signal_shift_pos_'+str(shift_size)] = df.groupby('group')['signal'].shift(shift_size).bfill(0)\n",
        "        df['signal_shift_neg_'+str(shift_size)] = df.groupby('group')['signal'].shift(-1*shift_size).ffill(0)\n",
        "        if diff & shift_size == 1:\n",
        "          df['signal_diff_pos_'+str(shift_size)] = df.groupby('group')['signal'].diff(shift_size).bfill(0)\n",
        "          df['signal_diff_neg_'+str(shift_size)] = df.groupby('group')['signal'].diff(-1*shift_size).ffill(0)\n",
        "\n",
        "    if add_pct_change:\n",
        "        df['pct_change'] = df['signal'].pct_change()\n",
        "        if add_pct_change_lag:\n",
        "            for shift_size in shift_sizes:    \n",
        "                df['pct_change_shift_pos_'+str(shift_size)] = df.groupby('group')['pct_change'].shift(shift_size).fillna(0)\n",
        "                df['pct_change_shift_neg_'+str(shift_size)] = df.groupby('group')['pct_change'].shift(-1*shift_size).fillna(0)\n",
        "\n",
        "    df['sig_power_1'] = df['signal']**2\n",
        "    df['sig_power_2'] = df['signal']**2\n",
        "    return df\n",
        "\n",
        "#Calculating the Mean Absolute Deviation\n",
        "def mean_abs_dev(val):\n",
        "  return np.mean(np.absolute(val - np.mean(val)))\n",
        "\n",
        "\n",
        "#Stretches the signal data(Time Series Data Augumentation)\n",
        "def stretch(data, rate=1):\n",
        "    input_length = data.shape[0]\n",
        "    data = librosa.effects.time_stretch(data, rate)\n",
        "    if len(data)>input_length:\n",
        "        data = data[:input_length]\n",
        "    else:\n",
        "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqbdeVPoSn0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Normalizing\n",
        "def std_sc(df,columns):\n",
        "  for x in columns:\n",
        "    df[x] = (df[x] - df[x].mean())/df[x].std()\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g562okSzSjZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Eval Metric For LightGBM\n",
        "def MacroF1Metric(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n",
        "    score = f1_score(labels, preds, average = 'macro')\n",
        "    return ('MacroF1Metric', score, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pL6itUOSX4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Custom Mish Activation Function\n",
        "def mish(x):\n",
        "\treturn tf.keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)\n",
        "get_custom_objects().update({'mish': Activation(mish)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gh2TYVCSMca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_one_sec_batch(df):\n",
        "  df['one_sec_batch'] = df.groupby(df.index//10_000).agg('ngroup').astype(np.int32)\n",
        "  return df\n",
        "\n",
        "def get_mini_batch(df):\n",
        "  df['mini_batch'] = df.groupby(df.index//5000).agg('ngroup').astype(np.int32)\n",
        "  return df\n",
        "\n",
        "def get_batches(df):\n",
        "  df['batch'] =  df.groupby(df.index//50_000).agg('ngroup').astype(np.int16)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDLMSdtxSVON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Anonymous Functions\n",
        "def reduce_mem_usage(df: pd.DataFrame,verbose: bool = True) -> pd.DataFrame:\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if (c_min > np.iinfo(np.int8).min\n",
        "                        and c_max < np.iinfo(np.int8).max):\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif (c_min > np.iinfo(np.int16).min\n",
        "                      and c_max < np.iinfo(np.int16).max):\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif (c_min > np.iinfo(np.int32).min\n",
        "                      and c_max < np.iinfo(np.int32).max):\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif (c_min > np.iinfo(np.int64).min\n",
        "                      and c_max < np.iinfo(np.int64).max):\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if (c_min > np.finfo(np.float16).min\n",
        "                        and c_max < np.finfo(np.float16).max):\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif (c_min > np.finfo(np.float32).min\n",
        "                      and c_max < np.finfo(np.float32).max):\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    reduction = (start_mem - end_mem) / start_mem\n",
        "\n",
        "    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n",
        "    if verbose:\n",
        "        print(msg)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def show(df,col,mask='open_channels',alpha=None):\n",
        "  for x in tqdm_notebook(np.sort(df[mask].unique())):\n",
        "    _=plt.plot(df[df[mask] == x][col],label=x,alpha=alpha)\n",
        "  _=plt.legend()\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "def submit(file):\n",
        "  submission.to_csv(f'{file}.csv',index=False,float_format='%.4f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-74mjeBWVRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#WaveNet Model\n",
        "def WaveNetResidualConv1D(num_filters, kernel_size, stacked_layer):\n",
        "\n",
        "    def build_residual_block(l_input):\n",
        "        resid_input = l_input\n",
        "        for dilation_rate in [2**i for i in range(stacked_layer)]:\n",
        "            l_sigmoid_conv1d = Conv1D(\n",
        "              num_filters, kernel_size, dilation_rate=dilation_rate,\n",
        "              padding='same', activation='sigmoid')(l_input)\n",
        "            l_tanh_conv1d = Conv1D(\n",
        "             num_filters, kernel_size, dilation_rate=dilation_rate,\n",
        "             padding='same', activation='mish')(l_input)\n",
        "            l_input = Multiply()([l_sigmoid_conv1d, l_tanh_conv1d])\n",
        "            l_input = Conv1D(num_filters, 1, padding='same')(l_input)\n",
        "            resid_input = Add()([resid_input ,l_input])\n",
        "        return resid_input\n",
        "    return build_residual_block\n",
        "def Classifier(shape_):\n",
        "    num_filters_ = 16\n",
        "    kernel_size_ = 3\n",
        "    stacked_layers_ = [12, 8, 4, 1]\n",
        "    l_input = Input(shape=(shape_))\n",
        "    x = Conv1D(num_filters_, 1, padding='same')(l_input)\n",
        "    x = WaveNetResidualConv1D(num_filters_, kernel_size_, stacked_layers_[0])(x)\n",
        "    x = Conv1D(num_filters_*2, 1, padding='same')(x)\n",
        "    x = WaveNetResidualConv1D(num_filters_*2, kernel_size_, stacked_layers_[1])(x)\n",
        "    x = Conv1D(num_filters_*4, 1, padding='same')(x)\n",
        "    x = WaveNetResidualConv1D(num_filters_*4, kernel_size_, stacked_layers_[2])(x)\n",
        "    x = Conv1D(num_filters_*8, 1, padding='same')(x)\n",
        "    x = WaveNetResidualConv1D(num_filters_*8, kernel_size_, stacked_layers_[3])(x)\n",
        "    l_output = Dense(1, activation='linear')(x)\n",
        "    model = models.Model(inputs=[l_input], outputs=[l_output])\n",
        "    opt = Adam(lr=LR)\n",
        "    opt = tfa.optimizers.SWA(opt)\n",
        "    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZQ7OxaRWbQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Custom Learning Schedule\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 40:\n",
        "        lr = LR\n",
        "    elif epoch < 50:\n",
        "        lr = LR / 2\n",
        "    elif epoch < 60:\n",
        "        lr = LR / 4\n",
        "    elif epoch < 75:\n",
        "        lr = LR / 6\n",
        "    elif epoch < 85:\n",
        "        lr = LR / 8\n",
        "    elif epoch < 100:\n",
        "        lr = LR / 10\n",
        "    else:\n",
        "        lr = LR / 12\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL04GQxNoTBp",
        "colab_type": "text"
      },
      "source": [
        "# Helper Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANhgACF_UPG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Eval Metric for Deep Neural Network\n",
        "class MacroF1(Callback):\n",
        "    def __init__(self, model, inputs, targets):\n",
        "        self.model = model\n",
        "        self.inputs = inputs\n",
        "        self.targets = np.argmax(targets, axis = 2).reshape(-1)\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        pred = np.argmax(self.model.predict(self.inputs), axis = 2).reshape(-1)\n",
        "        score = f1_score(self.targets, pred, average = 'macro')\n",
        "        print(f'F1 Macro Score: {score:.5f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR6F9755kgDj",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5656zp-X0Xb",
        "colab_type": "text"
      },
      "source": [
        "Signal Data is Cleaned with the Kalman filter to remove the noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvenkcI20DOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train_clean_kalman.csv')\n",
        "test = pd.read_csv('test_clean_kalman.csv')\n",
        "submission = pd.read_csv('sample_submission.csv.zip')\n",
        "test.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxkucbSk4fHH",
        "colab_type": "text"
      },
      "source": [
        "#### Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETqulNZvyr1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = get_one_sec_batch(train)\n",
        "test = get_one_sec_batch(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SREStiGibR_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = get_mini_batch(train)\n",
        "test = get_mini_batch(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J90WKxb_sl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = get_batches(train)\n",
        "test = get_batches(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75TPylhGX81j",
        "colab_type": "text"
      },
      "source": [
        "Grouping the data according the number of states that can occur in the signal range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj7Z-_CYxeYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_groups = {\n",
        "    0:[(0,1000000)],\n",
        "    1:[(1500000,2000000),(3500000,4000000)],\n",
        "    2:[(2500000,3000000),(4000000,4500000)],\n",
        "    3:[(1000000,1500000),(3000000,3500000)],\n",
        "    4:[(2000000,2500000),(4500000,5000000)]\n",
        "}\n",
        "\n",
        "train['group'] = -1\n",
        "for k,v in train_groups.items():\n",
        "    for l,r in v:\n",
        "        train.iloc[l:r,-1] = k\n",
        "\n",
        "\n",
        "test['group'] = -1\n",
        "test_groups = {\n",
        "    0:[(0,100000),(300000,400000),(800000,900000),(1000000,2000000)],\n",
        "    1:[(100000,200000),(900000,1000000)],\n",
        "    2:[(200000,300000),(600000,700000)],\n",
        "    3:[(400000,500000)],\n",
        "    4:[(500000,600000),(700000,800000)]\n",
        "}\n",
        "for k,v in test_groups.items():\n",
        "    for l,r in v:\n",
        "        test.iloc[l:r,-1] = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzklCt6UI5g",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9iiH7YpYgTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['has_10_states'] = np.where(train['group'] == 4,1,0)\n",
        "test['has_10_states'] = np.where(test['group'] == 4,1,0)\n",
        "\n",
        "min_mean_val = train[train['open_channels'] == 0]['signal'].mean()\n",
        "train['signal'] = np.where(train['has_10_states'] == 1,train['signal'] - (min_mean_val),train['signal'])\n",
        "test['signal'] = np.where(test['has_10_states'] == 1,test['signal'] - (min_mean_val),test['signal'])\n",
        "\n",
        "train.drop(columns=['has_10_states'],inplace=True)\n",
        "test.drop(columns=['has_10_states'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDRcLdrsDdzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['batch_sig_mean'] = train.groupby('batch')['signal'].transform('mean')\n",
        "train['batch_sig_std'] = train.groupby('batch')['signal'].transform('std')\n",
        "train['batch_sig_max'] = train.groupby('batch')['signal'].transform('max')\n",
        "train['batch_sig_min'] = train.groupby('batch')['signal'].transform('min')\n",
        "train['batch_sig_max_min_ratio'] = train['batch_sig_max'] / train['batch_sig_min']\n",
        "train['batch_sig_max_min_range'] = train['batch_sig_max'] - train['batch_sig_min']\n",
        "\n",
        "\n",
        "test['batch_sig_mean'] = test.groupby('batch')['signal'].transform('mean')\n",
        "test['batch_sig_std'] = test.groupby('batch')['signal'].transform('std')\n",
        "test['batch_sig_max'] = test.groupby('batch')['signal'].transform('max')\n",
        "test['batch_sig_min'] = test.groupby('batch')['signal'].transform('min')\n",
        "test['batch_sig_max_min_ratio'] = test['batch_sig_max'] / test['batch_sig_min']\n",
        "test['batch_sig_max_min_range'] = test['batch_sig_max'] - test['batch_sig_min']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gFdom3XbnAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['mini_batch_sig_mean'] = train.groupby('mini_batch')['signal'].transform('mean')\n",
        "train['mini_batch_sig_std'] = train.groupby('mini_batch')['signal'].transform('std')\n",
        "train['mini_batch_sig_max'] = train.groupby('mini_batch')['signal'].transform('max')\n",
        "train['mini_batch_sig_min'] = train.groupby('mini_batch')['signal'].transform('min')\n",
        "train['mini_batch_sig_max_min_ratio'] = train['mini_batch_sig_max'] / train['mini_batch_sig_min']\n",
        "train['mini_batch_sig_max_min_range'] = train['mini_batch_sig_max'] - train['mini_batch_sig_min']\n",
        "\n",
        "test['mini_batch_sig_mean'] = test.groupby('mini_batch')['signal'].transform('mean')\n",
        "test['mini_batch_sig_std'] = test.groupby('mini_batch')['signal'].transform('std')\n",
        "test['mini_batch_sig_max'] = test.groupby('mini_batch')['signal'].transform('max')\n",
        "test['mini_batch_sig_min'] = test.groupby('mini_batch')['signal'].transform('min')\n",
        "test['mini_batch_sig_max_min_ratio'] = test['mini_batch_sig_max'] / test['mini_batch_sig_min']\n",
        "test['mini_batch_sig_max_min_range'] = test['mini_batch_sig_max'] - test['mini_batch_sig_min']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBKbXmd-y9tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['one_sec_batch_sig_mean'] = train.groupby('one_sec_batch')['signal'].transform('mean')\n",
        "train['one_sec_batch_sig_std'] = train.groupby('one_sec_batch')['signal'].transform('std')\n",
        "train['one_sec_batch_sig_max'] = train.groupby('one_sec_batch')['signal'].transform('max')\n",
        "train['one_sec_batch_sig_min'] = train.groupby('one_sec_batch')['signal'].transform('min')\n",
        "train['one_sec_batch_sig_max_min_ratio'] = train['one_sec_batch_sig_max'] / train['one_sec_batch_sig_min']\n",
        "train['one_sec_batch_sig_max_min_range'] = train['one_sec_batch_sig_max'] - train['one_sec_batch_sig_min']\n",
        "\n",
        "test['one_sec_batch_sig_mean'] = test.groupby('one_sec_batch')['signal'].transform('mean')\n",
        "test['one_sec_batch_sig_std'] = test.groupby('one_sec_batch')['signal'].transform('std')\n",
        "test['one_sec_batch_sig_max'] = test.groupby('one_sec_batch')['signal'].transform('max')\n",
        "test['one_sec_batch_sig_min'] = test.groupby('one_sec_batch')['signal'].transform('min')\n",
        "test['one_sec_batch_sig_max_min_ratio'] = test['one_sec_batch_sig_max'] / test['one_sec_batch_sig_min']\n",
        "test['one_sec_batch_sig_max_min_range'] = test['one_sec_batch_sig_max'] - test['one_sec_batch_sig_min']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypxaXph2dIDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [x for x in train.columns[7:]]\n",
        "for x in cols:\n",
        "  train[f'{x}_msig'] = train[x] - train['signal']\n",
        "  test[f'{x}_msig'] = test[x] - test['signal']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l94YF9MnTEun",
        "colab_type": "code",
        "outputId": "a59d9dd6-98cd-4b9b-c991-a55cc197e344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "7182aa4d3c474a5aa0fb76674eb485ce",
            "c499188295e848d9b341293ee29eb752",
            "cfeb70ac13fa47698aff36ff946d9cb6",
            "8558a57d589e4c639f8c62a25d51d90d",
            "5c9ead65052d4080a4981ab3d4ec44d6",
            "5cc6a0bd8e1a455b8369bd3fd3091993",
            "6acb4ff1c980477aaa390f60f1e62ebb",
            "7a74748419cb430a966be0d7493c8f64",
            "1c37ec8bb7ce4432a4703307524af8cb",
            "77e8479da0f644a9b164752ae4477b76",
            "0be9ca6013e64feb8dba42d3558f89c3",
            "001d459adfa5465ea96204823b3b3c8a",
            "da97d871bf694286bc816ccc899c15c7",
            "b5a1e9fbaee84df59bbbf5d55af17373",
            "4d13b0814e8b45ae85cfae2f8d6d378d",
            "b1fe526fd55147babc4f6db7179f31f5"
          ]
        }
      },
      "source": [
        "add_pct_change = True\n",
        "diff = True\n",
        "add_pct_change_lag = False\n",
        "train = get_features(train,add_pct_change = add_pct_change,diff = diff,\n",
        "                        add_pct_change_lag = add_pct_change_lag)\n",
        "test = get_features(test,add_pct_change = add_pct_change,diff = diff,\n",
        "                        add_pct_change_lag = add_pct_change_lag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7182aa4d3c474a5aa0fb76674eb485ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c37ec8bb7ce4432a4703307524af8cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB5lxstkAx76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['roll5_sig_q8'] = train['signal'].rolling(5,min_periods=1).quantile(0.8)\n",
        "train['roll5_sig_q2'] = train['signal'].rolling(5,min_periods=1).quantile(0.2)\n",
        "train['roll5_sig_q9'] = train['signal'].rolling(5,min_periods=1).quantile(0.9)\n",
        "train['roll5_sig_q1'] = train['signal'].rolling(5,min_periods=1).quantile(0.1)\n",
        "\n",
        "test['roll5_sig_q8'] = test['signal'].rolling(5,min_periods=1).quantile(0.8)\n",
        "test['roll5_sig_q2'] = test['signal'].rolling(5,min_periods=1).quantile(0.2)\n",
        "test['roll5_sig_q9'] = test['signal'].rolling(5,min_periods=1).quantile(0.9)\n",
        "test['roll5_sig_q1'] = test['signal'].rolling(5,min_periods=1).quantile(0.1)\n",
        "\n",
        "train['sig_IDR_range'] = train['roll5_sig_q8'] - train['roll5_sig_q2']\n",
        "test['sig_IDR_range'] = test['roll5_sig_q8'] - test['roll5_sig_q2']\n",
        "\n",
        "train['sig_abs_IDR_range'] = np.abs(train['roll5_sig_q8'] - train['roll5_sig_q2'])\n",
        "test['sig_abs_IDR_range'] = np.abs(test['roll5_sig_q8'] - test['roll5_sig_q2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HGQfkM9KbTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['roll5_sig_std'] = train['signal'].rolling(5,min_periods=1).std()\n",
        "train['roll5_sig_roll5_max_std'] = train['signal'].rolling(5,min_periods=1).std().rolling(5,min_periods=1).max()\n",
        "test['roll5_sig_std'] = test['signal'].rolling(5,min_periods=1).std()\n",
        "test['roll5_sig_roll5_max_std'] = test['signal'].rolling(5,min_periods=1).std().rolling(5,min_periods=1).max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wex_uoG4nSNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['roll5_sig_std_IDR_range'] = train['roll5_sig_std'].rolling(5,min_periods=1).quantile(0.8) - train['roll5_sig_std'].rolling(5,min_periods=1).quantile(0.2)\n",
        "test['roll5_sig_std_IDR_range'] = test['roll5_sig_std'].rolling(5,min_periods=1).quantile(0.8) - test['roll5_sig_std'].rolling(5,min_periods=1).quantile(0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NHtTfcQDjSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = np.random.normal(0,0.001,train.shape[0])\n",
        "train['signal_with_sd_noise'] = train['signal'] + noise\n",
        "noise = np.random.normal(0,0.001,test.shape[0])\n",
        "test['signal_with_sd_noise'] = test['signal'] + noise[:test.shape[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGPBNS0rDb66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['rev_sig'] = -1 * train['signal']\n",
        "test['rev_sig'] = -1 * test['signal']\n",
        "\n",
        "train['signal_stretch'] = stretch(train['signal'].values,0.8)\n",
        "test['signal_stretch'] = stretch(test['signal'].values,0.8)\n",
        "\n",
        "train['signal_wave_pitch'] = librosa.effects.pitch_shift(np.array(train['signal']),10,n_steps=-5)\n",
        "test['signal_wave_pitch'] = librosa.effects.pitch_shift(np.array(test['signal']),10,n_steps=-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP5vn_VT-ngC",
        "colab_type": "text"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0xdpTt6hAFG",
        "colab_type": "code",
        "outputId": "8bea62f3-7ced-41d7-bebb-d307521fe990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "use_cols = [x for x in train.columns if x not in ['time', 'open_channels','batch', 'batch_slices', 'group','mini_batch','one_sec_batch']]\n",
        "use_cols,len(use_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['signal',\n",
              "  'batch_sig_mean',\n",
              "  'batch_sig_std',\n",
              "  'batch_sig_max',\n",
              "  'batch_sig_min',\n",
              "  'batch_sig_max_min_ratio',\n",
              "  'batch_sig_max_min_range',\n",
              "  'mini_batch_sig_mean',\n",
              "  'mini_batch_sig_std',\n",
              "  'mini_batch_sig_max',\n",
              "  'mini_batch_sig_min',\n",
              "  'mini_batch_sig_max_min_ratio',\n",
              "  'mini_batch_sig_max_min_range',\n",
              "  'one_sec_batch_sig_mean',\n",
              "  'one_sec_batch_sig_std',\n",
              "  'one_sec_batch_sig_max',\n",
              "  'one_sec_batch_sig_min',\n",
              "  'one_sec_batch_sig_max_min_ratio',\n",
              "  'one_sec_batch_sig_max_min_range',\n",
              "  'power',\n",
              "  'batch_sig_mean_msig',\n",
              "  'batch_sig_std_msig',\n",
              "  'batch_sig_max_msig',\n",
              "  'batch_sig_min_msig',\n",
              "  'batch_sig_max_min_ratio_msig',\n",
              "  'batch_sig_max_min_range_msig',\n",
              "  'mini_batch_sig_mean_msig',\n",
              "  'mini_batch_sig_std_msig',\n",
              "  'mini_batch_sig_max_msig',\n",
              "  'mini_batch_sig_min_msig',\n",
              "  'mini_batch_sig_max_min_ratio_msig',\n",
              "  'mini_batch_sig_max_min_range_msig',\n",
              "  'one_sec_batch_sig_mean_msig',\n",
              "  'one_sec_batch_sig_std_msig',\n",
              "  'one_sec_batch_sig_max_msig',\n",
              "  'one_sec_batch_sig_min_msig',\n",
              "  'one_sec_batch_sig_max_min_ratio_msig',\n",
              "  'one_sec_batch_sig_max_min_range_msig',\n",
              "  'power_msig',\n",
              "  'signal_shift_pos_1',\n",
              "  'signal_shift_neg_1',\n",
              "  'signal_diff_pos_1',\n",
              "  'signal_diff_neg_1',\n",
              "  'signal_shift_pos_2',\n",
              "  'signal_shift_neg_2',\n",
              "  'signal_shift_pos_3',\n",
              "  'signal_shift_neg_3',\n",
              "  'signal_diff_pos_3',\n",
              "  'signal_diff_neg_3',\n",
              "  'signal_shift_pos_4',\n",
              "  'signal_shift_neg_4',\n",
              "  'signal_shift_pos_5',\n",
              "  'signal_shift_neg_5',\n",
              "  'signal_diff_pos_5',\n",
              "  'signal_diff_neg_5',\n",
              "  'pct_change',\n",
              "  'sig_power',\n",
              "  'roll5_sig_q8',\n",
              "  'roll5_sig_q2',\n",
              "  'roll5_sig_q9',\n",
              "  'roll5_sig_q1',\n",
              "  'sig_IDR_range',\n",
              "  'sig_abs_IDR_range',\n",
              "  'roll5_sig_std',\n",
              "  'roll5_sig_roll5_max_std'],\n",
              " 65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJfRVRkbgi3z",
        "colab_type": "code",
        "outputId": "02eae930-6533-403f-8a5d-11ed81e47e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train = reduce_mem_usage(train)\n",
        "test = reduce_mem_usage(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 677.11 MB (74.2 % reduction)\n",
            "Mem. usage decreased to 268.94 MB (74.0 % reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZfj6oXVVMv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, valid_X, _, valid_y = train_test_split(train[use_cols],train['open_channels'],test_size=0.1)\n",
        "print(f'x_train shape => {valid_X.shape}, y_val shape => {valid_y.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t9A0L_DQQON",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3RBT-LarP1R",
        "colab_type": "text"
      },
      "source": [
        "## Tree Based Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKRt1C0w-6MZ",
        "colab_type": "text"
      },
      "source": [
        "### LightGBM Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCccapsl65ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "params = {'learning_rate': 0.098, \n",
        "          'max_depth': -1, \n",
        "          'num_leaves': 530,\n",
        "          'metric': 'rmse', \n",
        "          'random_state': 49, \n",
        "          'n_jobs':-1, \n",
        "          'feature_fraction': 0.8,\n",
        "          'bagging_fraction': 0.7,\n",
        "          'bagging_freq': 17,\n",
        "          'sample_fraction':0.89}\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxUQj1e1xFaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_groups = {\n",
        "    0:[(0,1000000)],\n",
        "    1:[(1500000,2000000),(3500000,4000000)],\n",
        "    2:[(2500000,3000000),(4000000,4500000)],\n",
        "    3:[(1000000,1500000),(3000000,3500000)],\n",
        "    4:[(2000000,2500000),(4500000,5000000)]\n",
        "}\n",
        "train['group_seg'] = -1\n",
        "for k,v in train_groups.items():\n",
        "    for l,r in v:\n",
        "        train.iloc[l:r,-1] = k\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcnhMrmXwuLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Custom Validation Data Split\n",
        "folds_valid = []\n",
        "for x in np.sort(train['group_seg'].unique()):\n",
        "    folds_valid.append(train[train['group_seg'] == x].index.tolist())\n",
        "        \n",
        "folds_train = []\n",
        "for x in  range(len(folds_valid)):\n",
        "    folds_train.append(train.loc[~train.index.isin(folds_valid[x])].index.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km8BENbvacP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_lgb = 0\n",
        "fold_score = []\n",
        "for i, (train_idx, val_idx) in enumerate(zip(folds_train,folds_valid)):\n",
        "  print(f'On fold {i}')\n",
        "  \n",
        "  x_train, x_val = train.iloc[train_idx][use_cols], train.iloc[val_idx][use_cols]\n",
        "  y_train, y_val = train.iloc[train_idx]['open_channels'], train.iloc[val_idx]['open_channels']\n",
        "\n",
        "  train_data = lgb.Dataset(x_train,label = y_train)\n",
        "  val_data = lgb.Dataset(x_val,label = y_val)\n",
        "\n",
        "  model = lgb.train(params, train_data, 2000,  val_data, \n",
        "                    verbose_eval=50, early_stopping_rounds=500, feval=MacroF1Metric)\n",
        "  \n",
        "  fold_score.append(f1_score(valid_y, np.round(np.clip(model.predict(valid_X),0,10)),average='macro'))\n",
        "  print(f\"F1 Score for fold {i} : {fold_score[-1]}\")\n",
        "\n",
        "  preds = model.predict(test[use_cols],num_iteration=model.best_iteration)\n",
        "  predictions_lgb += preds\n",
        "\n",
        "  del x_train,x_val,y_train,y_val,train_data,val_data\n",
        "  gc.collect()\n",
        "print(f'Mean Validation Score : {np.mean(fold_score)}')\n",
        "predictions_lgb /= 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEqSBybh-zdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_1 = np.round(np.clip(predictions_lgb,0,10)).astype(int)\n",
        "pd.Series(sub_1).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak-vf9XTwjT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['open_channels'] = sub_1\n",
        "show(test,'signal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ITZw2VjqVxF",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVDH9CogDu8O",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFcT8jliqcaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cols = [x for x in train.columns if x not in ['time', 'open_channels','batch', 'batch_slices', 'group','mini_batch']]\n",
        "norm_cols = [x for x in use_cols if x not in ['open_channels','has_10_states']]\n",
        "use_cols,len(use_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYlSW9-9qcXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SCALE = True\n",
        "if SCALE:\n",
        "  train = std_sc(train,norm_cols)\n",
        "  test = std_sc(test,norm_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNsJeoQXqgLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['group'] = train.groupby(train.index//4000).agg('ngroup').astype(np.int32)\n",
        "test['group'] = test.groupby(test.index//4000).agg('ngroup').astype(np.int32)\n",
        "group = train['group']\n",
        "kf = GroupKFold(n_splits=5)\n",
        "splits = [x for x in kf.split(train, train['open_channels'], group)]\n",
        "new_splits = []\n",
        "for sp in splits:\n",
        "    new_split = []\n",
        "    new_split.append(np.unique(group[sp[0]]))\n",
        "    new_split.append(np.unique(group[sp[1]]))\n",
        "    new_split.append(sp[1])    \n",
        "    new_splits.append(new_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyGfurG7oEKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train[use_cols]).reshape((-1,4000,train[use_cols].shape[1]))\n",
        "test_data = np.array(test[use_cols]).reshape((-1,4000,train[use_cols].shape[1]))\n",
        "train_target = np.array(pd.get_dummies(train['open_channels'])).reshape((-1,4000,11))\n",
        "train_data.shape, train_target.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLuG_RJFrAFX",
        "colab_type": "text"
      },
      "source": [
        "### WaveNet Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-G51JlzJAbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Enabling NVIDIA TESLA-P100 GPU Connection\n",
        "K.clear_session()\n",
        "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHPt6r8Iule",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.0001,patience=10,verbose=1)\n",
        "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.65,patience=10,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7scCz4i-pjfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 0.001\n",
        "cb_lr_schedule = LearningRateScheduler(lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofsa99qZrGS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = False\n",
        "seed_everything(42)\n",
        "oof_ = np.zeros((len(train), 11)) \n",
        "preds_ = np.zeros((len(test), 11))\n",
        "for n_fold, (tr_idx, val_idx, val_orig_idx) in enumerate(new_splits[0:], start=0):\n",
        "  print(f'On Fold :{n_fold}')\n",
        "  train_x, train_y = train_data[tr_idx], train_target[tr_idx]\n",
        "  valid_x, valid_y = train_data[val_idx], train_target[val_idx]\n",
        "  print(f'Our training dataset shape is {train_x.shape}')\n",
        "  print(f'Our validation dataset shape is {valid_x.shape}')\n",
        "\n",
        "  shape_ = (None, train_x.shape[2])\n",
        "  model = Classifier(shape_)\n",
        "  model.fit(train_x,train_y,\n",
        "            epochs=100,\n",
        "            callbacks=[cb_lr_schedule,MacroF1(model,valid_x,valid_y)],\n",
        "            batch_size=4,\n",
        "            validation_data=(valid_x,valid_y))\n",
        "  \n",
        "\n",
        "  preds_f = model.predict(valid_x)\n",
        "  f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  np.argmax(preds_f, axis=2).reshape(-1), average = 'macro')\n",
        "  print(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n",
        "  preds_f = preds_f.reshape(-1, preds_f.shape[-1])\n",
        "  oof_[val_orig_idx,:] += preds_f\n",
        "  te_preds = model.predict(test_data)\n",
        "  te_preds = te_preds.reshape(-1, te_preds.shape[-1])\n",
        "  preds_ += te_preds\n",
        "  preds_ = preds_ / 5\n",
        "f1_score_ = f1_score(np.argmax(train_target, axis = 2).reshape(-1),  np.argmax(oof_, axis = 1), average = 'macro') \n",
        "print(f'Training completed. oof macro f1 score : {f1_score_:1.5f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rErdUCoYPBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_2 = np.argmax(preds_, axis = 1).astype(int)\n",
        "pd.Series(sub_2).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8DCrNUkU0uY",
        "colab_type": "text"
      },
      "source": [
        "# Submtting the Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukcIpwQ1VHwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ensembleming 2 Models(LightGBM and WaveNet Predictions)\n",
        "submission['open_channels'] = (sub_1 + sub_2)/2.0\n",
        "submission['open_channels'] = submission['open_channels'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKi3VjLKYoTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv', index=False, float_format='%.4f')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}