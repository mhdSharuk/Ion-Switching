{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ion Switching dum1",
      "provenance": [],
      "collapsed_sections": [
        "xSzABZZskQKH",
        "kh_MRWlUkWfj",
        "YL04GQxNoTBp",
        "fR6F9755kgDj",
        "ERzklCt6UI5g",
        "y_hh-hK2-vQJ",
        "wX5aoY5FUv3C",
        "suVlLZNZAiZE",
        "rn3bDnsFBz2W",
        "MwW365uZDxvK",
        "HqnledmPB4tv"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1jpDwYksxiZ8BGcEO08l_qUKpZwHsgmtw",
      "authorship_tag": "ABX9TyMAkl+Xvi8QfUBIwrAv5mxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhdSharuk/Kaggle-Ion-Switching/blob/master/Ion_Switching_dum1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSzABZZskQKH",
        "colab_type": "text"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_EIYHDkzlH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import numba\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "pd.set_option('display.max_rows',None)\n",
        "pd.set_option('display.max_columns',None)\n",
        "import pywt\n",
        "from scipy import stats,signal\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('figure',figsize=(19,6))\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "import lightgbm as lgb\n",
        "from tqdm import tqdm_notebook\n",
        "from functools import partial\n",
        "from scipy import optimize\n",
        "from sklearn.metrics import f1_score\n",
        "import gc\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "logger = logging.getLogger('matplotlib.pyplot')\n",
        "logger.setLevel(logging.CRITICAL)\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense,Dropout, Conv1D, BatchNormalization, Activation, AveragePooling1D, GlobalAveragePooling1D, Lambda, Input, Concatenate, UpSampling1D, Multiply\n",
        "from keras.models import Model, Sequential\n",
        "from keras import backend as K\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.initializers import random_normal\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh_MRWlUkWfj",
        "colab_type": "text"
      },
      "source": [
        "# Connect to Kaggle CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhE7o8r7EgA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('./drive/My Drive/Ion Switching')\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pCT96Ny0Dhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWYXEdehkaRm",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGnjdU1RIePz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df: pd.DataFrame,verbose: bool = True) -> pd.DataFrame:\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if (c_min > np.iinfo(np.int8).min\n",
        "                        and c_max < np.iinfo(np.int8).max):\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif (c_min > np.iinfo(np.int16).min\n",
        "                      and c_max < np.iinfo(np.int16).max):\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif (c_min > np.iinfo(np.int32).min\n",
        "                      and c_max < np.iinfo(np.int32).max):\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif (c_min > np.iinfo(np.int64).min\n",
        "                      and c_max < np.iinfo(np.int64).max):\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if (c_min > np.finfo(np.float16).min\n",
        "                        and c_max < np.finfo(np.float16).max):\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif (c_min > np.finfo(np.float32).min\n",
        "                      and c_max < np.finfo(np.float32).max):\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    reduction = (start_mem - end_mem) / start_mem\n",
        "\n",
        "    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n",
        "    if verbose:\n",
        "        print(msg)\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZxR6Oau7QN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MacroF1Metric(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n",
        "    score = f1_score(labels, preds, average = 'macro')\n",
        "    return ('MacroF1Metric', score, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrfgzFI-LPUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_abs_dev(val):\n",
        "  return np.mean(np.absolute(val - np.mean(val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6rByYNbM5YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trend(df,abs_value=False):\n",
        "  idx = np.array(range(len(df)))\n",
        "  if abs:\n",
        "    df = np.abs(df)\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(idx.reshape(-1,1),df)\n",
        "  return lr.coef_[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCFO5IkVNYti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def change_rate(df):\n",
        "    change = (np.diff(df) / df[:-1])\n",
        "    change = change[np.nonzero(change)[0]]\n",
        "    change = change[~np.isnan(change)]\n",
        "    change = change[change != -np.inf]\n",
        "    change = change[change != np.inf]\n",
        "    return np.mean(change)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIoKvNaGb5ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_whole_rolling_feat(df,window):\n",
        "  first_batch = df['batch'].values[0]\n",
        "  mean_ = df[df['batch'] == first_batch]['signal'].mean()\n",
        "  std_ = df[df['batch'] == first_batch]['signal'].std()\n",
        "  var_ = df[df['batch'] == first_batch]['signal'].var()\n",
        "  min_ = df[df['batch'] == first_batch]['signal'].min()\n",
        "  max_ = df[df['batch'] == first_batch]['signal'].max()\n",
        "\n",
        "  for i in tqdm_notebook(window):\n",
        "    df[f'rolling_{i}_signal_mean'] = df['signal'].rolling(i).mean().replace([-np.nan,np.nan],mean_)\n",
        "    df[f'rolling_{i}_signal_std'] = df['signal'].rolling(i).std().replace([-np.nan,np.nan],std_)\n",
        "    df[f'rolling_{i}_signal_variance'] = df['signal'].rolling(i).var().replace([-np.nan,np.nan],var_)\n",
        "    df[f'rolling_{i}_signal_min'] = df['signal'].rolling(i).min().replace([-np.nan,np.nan],min_)\n",
        "    df[f'rolling_{i}_signal_max'] = df['signal'].rolling(i).max().replace([-np.nan,np.nan],max_)\n",
        "    df[f'rolling_{i}_abs_max_min_distance'] = np.absolute(df[f'rolling_{i}_signal_max'] - df[f'rolling_{i}_signal_min'])\n",
        "    df[f'rolling_{i}_maxtomin_ratio'] = np.absolute(np.divide(df[f'rolling_{i}_signal_max'],df[f'rolling_{i}_signal_min']))\n",
        "\n",
        "    cols = df.columns[-25:]\n",
        "    df[cols].fillna(0,inplace=True)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTROEmq_MVTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_whole_3_window_feat(df):\n",
        "    df['signal_whole_forward_mean'] = np.mean(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "    df['signal_whole_forward_sum'] = np.sum(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "    df['signal_whole_forward_median'] = np.median(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "    df['signal_whole_forward_min'] = np.min(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "    df['signal_whole_forward_max'] = np.max(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "    df['signal_whole_forward_var'] = np.var(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "    df['signal_whole_forward_std'] = np.std(df[['signal_shift_-1','signal_shift_-2','signal_shift_-3']],axis=1)\n",
        "\n",
        "    df['signal_whole_backward_mean'] = np.mean(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "    df['signal_whole_backward_sum'] = np.sum(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "    df['signal_whole_backward_median'] = np.median(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "    df['signal_whole_backward_min'] = np.min(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "    df['signal_whole_backward_max'] = np.max(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "    df['signal_whole_backward_var'] = np.var(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "    df['signal_whole_backward_std'] = np.std(df[['signal_shift_1','signal_shift_2','signal_shift_3']],axis=1)\n",
        "\n",
        "    cols = df.columns[-14:]\n",
        "    df[cols].fillna(0,inplace=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1QE0AIMszKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_whole_shift_window_feat(df,shift):\n",
        "  for s in tqdm_notebook(shift):\n",
        "    df[f'signal_shift_{s}'] = df['signal'].shift(s)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qax37A-a5fxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_dict(dict1,dict2):\n",
        "  return dict1.update((k, dict2[k]) for k in dict1.keys() & dict2.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHkGqyHx_KiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_df(df,keyval,columns):\n",
        "  for x in tqdm_notebook(columns):\n",
        "    if('batch_slices' in str(x)):\n",
        "      df[x] = df['batch_slices'].map(keyval[x])\n",
        "    else:\n",
        "      df[x] = df['batch'].map(keyval[x])\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duae7X0NLtWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feat(df, replace=True, create_3_state_feat=True, rolling_feat=True, shift_feat=True):\n",
        "  if create_3_state_feat:\n",
        "    for x in tqdm_notebook(['batch','batch_slices','group']):\n",
        "      df[f'{x}_backward_s1'] = df.groupby(x)['signal'].shift(1)\n",
        "      df[f'{x}_backward_s2'] = df.groupby(x)['signal'].shift(2)\n",
        "      df[f'{x}_backward_s3'] = df.groupby(x)['signal'].shift(3)\n",
        "\n",
        "      df[f'{x}_backward_mean'] = np.mean(df[[f'{x}_backward_s1',f'{x}_backward_s2',f'{x}_backward_s3']],axis=1)\n",
        "      df[f'{x}_backward_sum'] = np.sum(df[[f'{x}_backward_s1',f'{x}_backward_s2',f'{x}_backward_s3']],axis=1)\n",
        "      df[f'{x}_backward_min'] = np.min(df[[f'{x}_backward_s1',f'{x}_backward_s2',f'{x}_backward_s3']],axis=1)\n",
        "      df[f'{x}_backward_max'] = np.max(df[[f'{x}_backward_s1',f'{x}_backward_s2',f'{x}_backward_s3']],axis=1)\n",
        "\n",
        "      df[f'{x}_forward_s1'] = df.groupby(x)['signal'].shift(-1)\n",
        "      df[f'{x}_forward_s2'] = df.groupby(x)['signal'].shift(-2)\n",
        "      df[f'{x}_forward_s3'] = df.groupby(x)['signal'].shift(-3)\n",
        "\n",
        "      df[f'{x}_forward_mean'] = np.mean(df[[f'{x}_forward_s1',f'{x}_forward_s2',f'{x}_forward_s3']],axis=1)\n",
        "      df[f'{x}_forward_sum'] = np.sum(df[[f'{x}_forward_s1',f'{x}_forward_s2',f'{x}_forward_s3']],axis=1)\n",
        "      df[f'{x}_forward_min'] = np.min(df[[f'{x}_forward_s1',f'{x}_forward_s2',f'{x}_forward_s3']],axis=1)\n",
        "      df[f'{x}_forward_max'] = np.max(df[[f'{x}_forward_s1',f'{x}_forward_s2',f'{x}_forward_s3']],axis=1)\n",
        "\n",
        "  \"\"\"if rolling_feat:\n",
        "      for x in [50,100,5000,10000]:\n",
        "        df[f'rolling_{x}_mean'] = df['signal'].rolling(x).mean()\"\"\"\n",
        "  if replace:\n",
        "    df.fillna(0,inplace=True)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL04GQxNoTBp",
        "colab_type": "text"
      },
      "source": [
        "# Helper Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA1fEzgDgf6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastSignal():\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "\n",
        "  def create_mav(self):\n",
        "    for x in ['batch']:\n",
        "      self.df[f'{x}_mav'] = self.df.groupby(x)['signal'].transform(lambda x:np.mean(np.abs(x)))\n",
        "    \n",
        "  def create_iav(self):\n",
        "    for x in ['batch']:  \n",
        "      self.df[f'{x}_iav'] = self.df.groupby(x)['signal'].transform(lambda x: np.sum(np.abs(x)))\n",
        "\n",
        "  def create_mav_slope(self):\n",
        "    for x in ['batch']:\n",
        "      self.df[f'{x}_mav_slope'] = self.df[f'{x}_mav'].shift(-1) - self.df[f'{x}_mav']\n",
        "  \n",
        "  def create_rms(self):\n",
        "    for x in ['batch']:\n",
        "      self.df[f'{x}_rms'] = self.df.groupby(x)['signal'].transform(lambda x:np.sqrt(np.mean(np.power(x,2))))\n",
        "      \n",
        "  def get_zero_crossing(self):\n",
        "    self.df[f'batch_zer_crossing'] = self.df.groupby('batch')['signal'].apply(lambda x:np.sum(librosa.zero_crossings(np.array(x),pad=False)))\n",
        "\n",
        "  def get_shape_factor(self):\n",
        "    self.df[f'batch_shape_factor'] = self.df.groupby('batch')['signal'].transform(lambda x: np.divide(np.sqrt(np.mean(np.power(x,2))),np.mean(np.abs(x))))\n",
        "\n",
        "  def get_crest_factor(self):\n",
        "    self.df[f'batch_crest_factor'] = self.df.groupby('batch')['signal'].transform(lambda x: np.divide(np.max(np.abs(x)),np.sqrt(np.mean(np.power(x,2)))))  \n",
        "\n",
        "  def get_margin_factor(self):\n",
        "    for x in ['batch']:\n",
        "      self.df[f'{x}_margin_factor'] = self.df.groupby(x)['signal'].transform(lambda x:np.divide(np.max(np.abs(x)), np.power(np.mean(np.sqrt(np.abs(x))),2)))\n",
        "\n",
        "  def get_impulse_factor(self):\n",
        "    self.df[f'batch_impulse_factor'] = self.df.groupby('batch')['signal'].transform(lambda x:np.divide(np.max(np.abs(x)), np.mean(np.abs(x))))\n",
        "\n",
        "  def create_features(self):\n",
        "    self.get_impulse_factor()\n",
        "    self.get_margin_factor()\n",
        "    self.get_shape_factor()\n",
        "    self.get_crest_factor()\n",
        "    self.get_zero_crossing()\n",
        "    self.create_rms()\n",
        "    self.create_mav()\n",
        "    self.create_mav_slope()\n",
        "    self.create_iav()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sevFVh4H9jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IonDataset:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtUGYihDoYf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataPipeLine:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def get_batch(self,df):\n",
        "    df.sort_values(by=['time'],inplace=True)\n",
        "    df.index = ((df.time * 10_000) - 1).values\n",
        "    df['batch'] = df.index // 50_000\n",
        "    df['batch_slices'] = (df.index - (df.batch * 50_000)) // 5000\n",
        "    return df\n",
        "\n",
        "  def group_data(self,df_train,df_test,group):\n",
        "    print(f\"Grouping Data {group}\")\n",
        "    self.group = group\n",
        "    data_groups = (df_train.query(f\"group == {self.group}\"),df_test.query(f\"group == {self.group}\"))\n",
        "    return data_groups\n",
        "    \n",
        "  def get_signal_shifting(self,df,window_sizes):\n",
        "    self.window_shift = window_sizes\n",
        "    self.df = df\n",
        "    for i in self.window_shift:\n",
        "      i = int(i)\n",
        "      print(f\"Shifting Signals {i} size\")\n",
        "      self.df[f'signal_shift_{i}'] = self.df.signal.shift(i)\n",
        "    return self.df\n",
        "\n",
        "  def get_features_per_group(self,df,feat_per_batch = False):\n",
        "    self.data = df\n",
        "    for x in tqdm_notebook(self.data.group.unique()):\n",
        "      d = {}\n",
        "      if not feat_per_batch:\n",
        "        for i in ['mean','median','std','var','min','max','sem','sum','cumsum','skew','mad']:\n",
        "          d[f'group_{i}'] = self.data.groupby('group')['signal'].agg(i).to_dict()\n",
        "        d[f'group_max_neg_signal'] = self.data[self.data['signal']<0].groupby('group')['signal'].min().to_dict()\n",
        "        d[f'group_min_neg_signal'] = self.data[self.data['signal']<0].groupby('group')['signal'].max().to_dict()\n",
        "        d[f'group_min_pos_signal'] = self.data[self.data['signal']>0].groupby('group')['signal'].min().to_dict()\n",
        "        d[f'group_max_pos_signal'] = self.data[self.data['signal']>0].groupby('group')['signal'].max().to_dict()\n",
        "\n",
        "      else:\n",
        "        for i in ['batch','batch_slices']:\n",
        "          for j in ['mean','median','std','var','min','max','sem','sum','cumsum','skew','mad']:\n",
        "            d[f'group_{i}_{j}'] = self.data.groupby(['group',i])['signal'].agg(j).to_dict()\n",
        "    return d\n",
        "  \n",
        "  def get_batch_feat(self,df):\n",
        "    d = {}\n",
        "    for x in tqdm_notebook(['batch','batch_slices']):\n",
        "      for i in ['mean','median','std','var','min','max','sem','sum','cumsum','skew','mad']:\n",
        "        d[f'{x}_{i}'] = df.groupby(x)['signal'].agg(i).to_dict()\n",
        "    return d\n",
        "  def get_nearest_feat(self,df):\n",
        "    print(\"Creating Previous Features\")\n",
        "    df['c1'] = df.groupby('group')['signal'].shift(1) \n",
        "    df['c2'] = df.groupby('group')['signal'].shift(2) \n",
        "    df['c3'] = df.groupby('group')['signal'].shift(3)\n",
        "\n",
        "    df['group_prev_3_sum'] = df[['c1','c2','c3']].sum(axis=1)\n",
        "    df['group_prev_3_mean'] = df[['c1','c2','c3']].mean(axis=1)\n",
        "    df['group_prev_3_min'] = df[['c1','c2','c3']].min(axis=1)\n",
        "    df['group_prev_3_max'] = df[['c1','c2','c3']].max(axis=1)\n",
        "    df['group_prev_3_std'] = df[['c1','c2','c3']].std(axis=1)\n",
        "    df['group_prev_3_var'] = df[['c1','c2','c3']].var(axis=1)\n",
        "    df['group_prev_3_mad'] = df[['c1','c2','c3']].mad(axis=1)\n",
        "\n",
        "    print(\"Creating Forward Features\")\n",
        "    df['c1'] = df.groupby('group')['signal'].shift(-1) \n",
        "    df['c2'] = df.groupby('group')['signal'].shift(-2) \n",
        "    df['c3'] = df.groupby('group')['signal'].shift(-3)\n",
        "    df['group_forw_3_sum'] = df[['c1','c2','c3']].sum(axis=1)\n",
        "    df['group_forw_3_mean'] = df[['c1','c2','c3']].mean(axis=1)\n",
        "    df['group_forw_3_min'] = df[['c1','c2','c3']].min(axis=1)\n",
        "    df['group_forw_3_max'] = df[['c1','c2','c3']].max(axis=1)\n",
        "    df['group_forw_3_std'] = df[['c1','c2','c3']].std(axis=1)\n",
        "    df['group_forw_3_var'] = df[['c1','c2','c3']].var(axis=1)\n",
        "    df['group_forw_3_mad'] = df[['c1','c2','c3']].mad(axis=1)\n",
        "    df.drop(columns=['c1','c2','c3'],inplace=True)\n",
        "    return df\n",
        "\n",
        "pipe = DataPipeLine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4MbzQYkoVfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LGB:\n",
        "  def __init__(self,train_data,test_data,params,metric):\n",
        "    self.train = train_data\n",
        "    self.test = test_data\n",
        "    self.params = params\n",
        "    self.metric = metric\n",
        "\n",
        "  def remove_cols(self,cols):\n",
        "    print(\"Removing the inappropriate columns\")\n",
        "    self.used_cols = [x for x in self.train.columns if x not in cols]\n",
        "    self.train = self.train[self.used_cols]\n",
        "    self.used_cols.remove('open_channels')\n",
        "    self.test = self.test[self.used_cols]\n",
        "\n",
        "  def split_data(self,split_val,for_train=False,for_test=True):\n",
        "    print(\"Splitting the data\")\n",
        "    if (for_train == for_test):\n",
        "      raise \"Data Cannot be splitted for both Train and Test Data\"\n",
        "    elif(for_test):\n",
        "      self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.train[self.used_cols],self.train['open_channels'],test_size=split_val)\n",
        "    else:\n",
        "      self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.train[self.used_cols],self.train['open_channels'],train_size=split_val)\n",
        "  \n",
        "  def get_params(self):\n",
        "    return self.params\n",
        "\n",
        "  def set_params(self,params):\n",
        "    print(\"Updated the params values\")\n",
        "    self.params.update(params)\n",
        "\n",
        "  def eval_metric(self,metric):\n",
        "    self.eval_metric = metric\n",
        "\n",
        "  def start_training(self):\n",
        "    print(\"Started Training\")\n",
        "    self.model = lgb.train(self.params,\n",
        "                           lgb.Dataset(self.x_train,self.y_train),\n",
        "                           2000,lgb.Dataset(self.x_val,self.y_val),\n",
        "                           verbose_eval=100,\n",
        "                           early_stopping_rounds=500,feval=self.metric)\n",
        "  def predict(self):\n",
        "    print(\"Predictting the Unknown Data\")\n",
        "    predict_dict = {int(x):0 for x in self.test.index}\n",
        "    self.predictions = self.model.predict(self.test)\n",
        "    for (x,y) in enumerate(predict_dict.keys()):\n",
        "      predict_dict[y] = self.predictions[x] \n",
        "    return predict_dict\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN0bPW64xrM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OptimizedRounder(object):\n",
        "  def __int__(self):\n",
        "    self.coef_ = 0\n",
        "  \n",
        "  def _MacroF1_loss(self,coef,X,y):\n",
        "    X_p = pd.cut(X,[-np.inf] + list(np.sort(coef)) + [np.inf], labels=np.linspace(0,10,11).tolist())\n",
        "\n",
        "    return -f1_score(y, X_p, average = 'macro')\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    loss_partial = partial(self._MacroF1_loss,X=X, y=y)\n",
        "    initial_coef = np.linspace(0,10,21).tolist()[:-1]\n",
        "    self.coef_ = optimize.minimize(loss_partial,initial_coef,method='nelder-mead')\n",
        "\n",
        "  def predict(self, X, coef):\n",
        "    return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=np.linspace(0,10,11).tolist())\n",
        "\n",
        "  def round_prediction(self,prediction,coefficients):\n",
        "    prediction = np.array(prediction)\n",
        "    prediction[prediction <= coefficients[0]] = 0\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[0], prediction <= coefficients[1]))] = 1\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[1], prediction <= coefficients[2]))] = 2\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[2], prediction <= coefficients[3]))] = 3\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[3], prediction <= coefficients[4]))] = 4\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[4], prediction <= coefficients[5]))] = 5\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[5], prediction <= coefficients[6]))] = 6\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[6], prediction <= coefficients[7]))] = 7\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[7], prediction <= coefficients[8]))] = 8\n",
        "    prediction[np.where(np.logical_and(prediction > coefficients[8], prediction <= coefficients[9]))] = 9\n",
        "    prediction[prediction > coefficients[9]] = 10\n",
        "    \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o2mrWTXP_eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class macroF1(Callback):\n",
        "    def __init__(self, model, inputs, targets):\n",
        "        self.model = model\n",
        "        self.inputs = inputs\n",
        "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
        "        f1_val = f1_score(self.targets, pred, average=\"macro\")\n",
        "        print(\"val_f1_macro_score: \", f1_val)\n",
        "                \n",
        "def model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n",
        "    hist = model.fit_generator(\n",
        "        Datagen(train_inputs, train_targets, batch_size, is_train=True),\n",
        "        steps_per_epoch = len(train_inputs) // batch_size,\n",
        "        epochs = n_epoch,\n",
        "        validation_data=Datagen(val_inputs, val_targets, batch_size),\n",
        "        validation_steps = len(val_inputs) // batch_size,\n",
        "        callbacks = [lr_schedule, macroF1(model, val_inputs, val_targets)],\n",
        "        shuffle = False,\n",
        "        verbose = 1\n",
        "        )\n",
        "    return hist\n",
        "\n",
        "\n",
        "def lrs(epoch):\n",
        "    if epoch<35:\n",
        "        lr = learning_rate\n",
        "    elif epoch<50:\n",
        "        lr = learning_rate/10\n",
        "    else:\n",
        "        lr = learning_rate/100\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR6F9755kgDj",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvenkcI20DOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train_clean.csv')\n",
        "test = pd.read_csv('test_clean.csv')\n",
        "submission = pd.read_csv('sample_submission.csv.zip')\n",
        "\n",
        "test.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxkucbSk4fHH",
        "colab_type": "text"
      },
      "source": [
        "#### Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84yjL2eoPg-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = DataPipeLine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux2ETdtlVW2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pipe.get_batch(train)\n",
        "test = pipe.get_batch(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H89gS12D5uM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['group'] = -1\n",
        "x = [(0,500000),(1000000,1500000),(1500000,2000000),(2500000,3000000),(2000000,2500000)]\n",
        "for k in range(5): train.loc[x[k][0]:x[k][1],'group'] = k\n",
        "#train = train[train['group'] != -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvbfG-JS5k44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['group'] = -1\n",
        "x = [[(0,100000),(300000,400000),(800000,900000),(1000000,2000000)],[(400000,500000)], \n",
        "     [(100000,200000),(900000,1000000)],[(200000,300000),(600000,700000)],[(500000,600000),(700000,800000)]]\n",
        "for k in range(5):\n",
        "    for j in range(len(x[k])): test.iloc[x[k][j][0]:x[k][j][1],4] = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5yMP1CvWuSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape\n",
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN3fVXqFTwi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzklCt6UI5g",
        "colab_type": "text"
      },
      "source": [
        "# Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWL7UKZmUM-u",
        "colab_type": "text"
      },
      "source": [
        "#### OOP Way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koFuV9vWHj6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pipe.get_signal_shifting(train,(np.linspace(-3,3,7)))\n",
        "\n",
        "agg_group_feat = pipe.get_features_per_group(train)\n",
        "for x in tqdm_notebook(agg_group_feat.keys()):\n",
        "  train[x] = train['group'].map(agg_group_feat[x])\n",
        "batch_features = pipe.get_batch_feat(train)\n",
        "for x in tqdm_notebook(batch_features.keys()):\n",
        "  if 'batch_slices' in x:\n",
        "    train[x] = train['batch_slices'].map(batch_features[x])\n",
        "  else:\n",
        "    train[x] = train['batch'].map(batch_features[x])\n",
        "train = pipe.get_nearest_feat(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAUCMHRxPaQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pipe.get_signal_shifting(test,(np.linspace(-3,3,7)))\n",
        "agg_group_feat = pipe.get_features_per_group(test)\n",
        "for x in tqdm_notebook(agg_group_feat.keys()):\n",
        "  test[x] = test['group'].map(agg_group_feat[x])\n",
        "batch_features = pipe.get_batch_feat(test)\n",
        "for x in tqdm_notebook(batch_features.keys()):\n",
        "  if 'batch_slices' in x:\n",
        "    test[x] = test['batch_slices'].map(batch_features[x])\n",
        "  else:\n",
        "    test[x] = test['batch'].map(batch_features[x])\n",
        "test = pipe.get_nearest_feat(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXBaAc3YYvZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for df in tqdm_notebook([train,test]):\n",
        "  for x in ['batch','batch_slices']:\n",
        "    df[f'{x}_range'] = df[f'{x}_max'] - df[f'{x}_min']\n",
        "    df[f'{x}_min_max_ratio'] = df[f'{x}_max']/df[f'{x}_min']\n",
        "    df[f'{x}_abs_max'] = np.absolute(df[f'{x}_max'])\n",
        "    df[f'{x}_abs_min'] = np.absolute(df[f'{x}_min'])\n",
        "    df[f'{x}_abs_avg'] = (df[f'{x}_abs_max'] + df[f'{x}_abs_min'])//2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r76QdmbrIIVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = train.columns[6:]\n",
        "for df in [train,test]:\n",
        "  for x in tqdm_notebook(columns):\n",
        "    df[str(x)+'_msig'] = df[str(x)] - df['signal']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEFkPWdMWQWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.fillna(0,inplace=True)\n",
        "test.fillna(0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPyTU-kYZd15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_groups = []\n",
        "for i in [0,1,2,3,4]:\n",
        "  data_groups.append(pipe.group_data(train,test,i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukP5LKqu-Nd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "assert train.shape[1]-1 == test.shape[1],\"Train and Test shape doesn't match\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryEU3Ekg-n8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[x for x in train.columns if x not in test.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdcaCreG0DCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNmDZAEToNlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = int(train.shape[0] - train.shape[0]*0.1)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYY4fx_p9y0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = reduce_mem_usage(train)\n",
        "test = reduce_mem_usage(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9n12xMzRAt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'learning_rate': 0.07, \n",
        "          'max_depth': -1, \n",
        "          'num_leaves': 200,\n",
        "          'metric': 'logloss', \n",
        "          'random_state': 7, \n",
        "          'n_jobs':-1, \n",
        "          'sample_fraction':0.33}\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUu1A48Q3Ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,5):\n",
        "  print(data_groups[i][0].group.unique(),\n",
        "        data_groups[i][1].group.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miernt5CQ3HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['time', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']\n",
        "model_group_0 = LGB(data_groups[0][0],data_groups[0][1],params,MacroF1Metric)\n",
        "model_group_1 = LGB(data_groups[1][0],data_groups[1][1],params,MacroF1Metric)\n",
        "model_group_2 = LGB(data_groups[2][0],data_groups[2][1],params,MacroF1Metric)\n",
        "model_group_3 = LGB(data_groups[3][0],data_groups[3][1],params,MacroF1Metric)\n",
        "model_group_4 = LGB(data_groups[4][0],data_groups[4][1],params,MacroF1Metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mXjsOnLYyeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_group_0.remove_cols(cols)\n",
        "model_group_1.remove_cols(cols)\n",
        "model_group_2.remove_cols(cols)\n",
        "model_group_3.remove_cols(cols)\n",
        "model_group_4.remove_cols(cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaou7dURf79_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPLIT = 0.15\n",
        "model_group_0.split_data(SPLIT)\n",
        "model_group_1.split_data(SPLIT)\n",
        "model_group_2.split_data(SPLIT)\n",
        "model_group_3.split_data(SPLIT)\n",
        "model_group_4.split_data(SPLIT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnZinTKbaM-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_dict = {x:0 for x in test.index}\n",
        "len(predictions_dict.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et494s8JcPH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_group_0.start_training()\n",
        "predictions_dict.update(model_group_0.predict())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKEbwAu_ns0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_group_1.start_training()\n",
        "predictions_dict.update(model_group_1.predict())\n",
        "model_group_2.start_training()\n",
        "predictions_dict.update(model_group_2.predict())\n",
        "model_group_3.start_training()\n",
        "predictions_dict.update(model_group_3.predict())\n",
        "model_group_4.start_training()\n",
        "predictions_dict.update(model_group_4.predict())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymgbo5i2Ul8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = [x for (y,x) in predictions_dict.items()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpzYV1Vu0C87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "round_pred = np.round(np.clip(preds[:2000000], 0, 10)).astype(int)\n",
        "sub['open_channels'] = round_pred\n",
        "sub['open_channels'].value_counts()\n",
        "sub.to_csv('submission.csv', index=False, float_format='%.4f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEP9e_n_UXKs",
        "colab_type": "text"
      },
      "source": [
        "#### Functional Way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD96dOPsJPfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = get_group_channel_agg(train,test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK6ey0yCJPRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.fillna(0,inplace=True)\n",
        "test.fillna(0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_K7IfYiLzuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = get_feat(train,replace=True,create_3_state_feat=True,rolling_feat=True,shift_feat=True)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2IG_XzEgoAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = get_feat(test,replace=True,create_3_state_feat=True,rolling_feat=True,shift_feat=True)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoslbghOzamt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = get_whole_shift_window_feat(train,np.linspace(-10,10,21,dtype=np.int))\n",
        "test = get_whole_shift_window_feat(test,np.linspace(-10,10,21,dtype=np.int))\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06FmsMq3NwL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = create_whole_3_window_feat(train)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouaIzoe9OndJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = create_whole_3_window_feat(test)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUliu6MKMBB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"train = get_whole_rolling_feat(train,[10,50,100,1000,10000])\n",
        "gc.collect()\n",
        "test = get_whole_rolling_feat(test,[10,50,100,1000,10000])\n",
        "gc.collect()\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9TR7rzoJX-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.fillna(0,inplace=True)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOeZhmtwJYgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.fillna(0,inplace=True)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9UFYu7y9YaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = list(set(x for x in train.columns if 'batch_slices' in x).union(set(x for x in train.columns if 'batch' in x)))\n",
        "for x in tqdm_notebook(sub):\n",
        "  train[f'{x}_msignal'] = train[x] - train['signal']\n",
        "\n",
        "for x in tqdm_notebook(sub):\n",
        "  test[f'{x}_msignal'] = test[x] - test['signal']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "142ZDgf7g8qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = reduce_mem_usage(train)\n",
        "test = reduce_mem_usage(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEP-F2tHdD1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'train shape => {train.shape}')\n",
        "print(f'test shape => {test.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SU1KwBadNTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP5vn_VT-ngC",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_hh-hK2-vQJ",
        "colab_type": "text"
      },
      "source": [
        "#### If save data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4e9NaPiIrtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE = False\n",
        "if SAVE:\n",
        "  train.to_csv(\"train_all_feat.csv\",index=False)\n",
        "  test.to_csv(\"test_all_feat.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkXOHOD4-rwM",
        "colab_type": "text"
      },
      "source": [
        "#### Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn_t3fq8OZJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3ox2zQOZGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Y_iVEiOZET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcpbjtBwOZAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbXYeAIPOY_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ6o9WAaOY8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxZhwYJ3OY5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0vc4_dlOY3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5IKRngqOY0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsagMfnhOYyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxFbvH_FVE0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_value = train.shape[0] - train.shape[0]*0.1\n",
        "split_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0xdpTt6hAFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cols = [x for x in train.columns if x not in ['time', 'open_channels', 'batch', 'batch_slices', 'group']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZfj6oXVVMv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(train[use_cols],train['open_channels'],test_size=0.15)\n",
        "print(f'x_train shape => {x_train.shape[0]}, y_train shape => {y_train.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGrsleJWJQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'learning_rate': 0.08, \n",
        "          'max_depth': -1, \n",
        "          'num_leaves': 250,\n",
        "          'metric': 'rmse', \n",
        "          'random_state': 7, \n",
        "          'n_jobs':-1, \n",
        "          'sample_fraction':0.43}\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t9A0L_DQQON",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKRt1C0w-6MZ",
        "colab_type": "text"
      },
      "source": [
        "## LightGBM Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihkW6w_68uVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lgb.train(params, lgb.Dataset(x_train, y_train), 2000,  lgb.Dataset(x_val, y_val), verbose_eval=50, early_stopping_rounds=500, feval=MacroF1Metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPuHvYBrOxox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_MODEL = False\n",
        "if SAVE_MODEL:\n",
        "  model.save_model('lgb_cv_93844.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz6htk0j_neE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(test[use_cols], num_iteration=model.best_iteration)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zene-auLQfag",
        "colab_type": "text"
      },
      "source": [
        "## Unet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_sQdhs_QjHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "model = Unet()\n",
        "print(model.summary())\n",
        "\n",
        "learning_rate=0.005\n",
        "n_epoch=60\n",
        "batch_size=32\n",
        "\n",
        "lr_schedule = LearningRateScheduler(lrs)\n",
        "\n",
        "#classifier\n",
        "model.compile(loss=categorical_crossentropy, \n",
        "              optimizer=Adam(lr=learning_rate), \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "hist = model_fit(model, train_input, train_target, val_input, val_target, n_epoch, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8DCrNUkU0uY",
        "colab_type": "text"
      },
      "source": [
        "# Submtting the Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-29Qre0cxmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "round_pred = np.round(np.clip(preds, 0, 10)).astype(int)\n",
        "submission['open_channels'] = round_pred\n",
        "submission['open_channels'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKi3VjLKYoTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission_2.csv', index=False, float_format='%.4f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng9ELI8AlTnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions submit -c liverpool-ion-switching -f submission_2.csv -m \"0.93844 \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX5aoY5FUv3C",
        "colab_type": "text"
      },
      "source": [
        "# Feature Importance Scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ZnNAiIc9HP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITb9fYEdlTlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb.plot_importance(model,importance_type='split', max_num_features=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suVlLZNZAiZE",
        "colab_type": "text"
      },
      "source": [
        "# ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn3bDnsFBz2W",
        "colab_type": "text"
      },
      "source": [
        "#### For Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luKG_tBwbLS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()\n",
        "train2 = train.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOzcRoLqcZup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in train.group.unique():\n",
        "  plt.plot(train[train['group'] == x]['signal'][::100],'.',label=f'signal group {x}')\n",
        "plt.plot(train['group'],label='groups',color='black')\n",
        "for i in range(10):\n",
        "  plt.plot([i*5e5,i*5e5],[-4,12],'r')\n",
        "for i in range(10):\n",
        "  plt.text(i*5e5+2e5,10,str(i+1),size=20)\n",
        "plt.yticks(np.linspace(-4,12,17))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcyMClBjbLIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(19,6))\n",
        "res = 1000\n",
        "plt.plot(range(0,train.shape[0],res),train['open_channels'][0::res])\n",
        "plt.yticks([0,1,2,3,4,5,6,7,8,9,10])\n",
        "for i in range(10):\n",
        "  plt.plot([i*5e5,i*5e5],[0,10],'r')\n",
        "for i in range(10):\n",
        "  plt.text(i*500000+200000,10,str(i+1),size=20)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9Cbb8YbK_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(19,5)) \n",
        "res = 1000\n",
        "plt.plot(range(0,train.shape[0],res),train['signal'][0::res])\n",
        "for i in range(10):\n",
        "  plt.plot([i*500000,i*500000],[-4,12],'r')\n",
        "for j in range(10):\n",
        "    plt.plot([j*100000,j*100000],[-4,12],'r:')\n",
        "for i in range(10):\n",
        "  plt.text(i*500000+200000,10,str(i+1),size=20)\n",
        "plt.xticks(np.linspace(0,5e6,11))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjwV1bDEG5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = train[train['signal'] == -1.817]\n",
        "df2 = train[train['signal'] == 3.186]\n",
        "df3 = train[train['signal'] == 325]\n",
        "\n",
        "plt.plot(train['signal'][::1000],alpha=1)\n",
        "plt.plot(df1['signal'],alpha=1,label='df1')\n",
        "plt.plot(df2['signal'],alpha=1,label='df2')\n",
        "plt.plot(df3['signal'],alpha=1,label='df3')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa-jAltv5aYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slope, intercept, rval, pval, stderr = stats.linregress(train['time'][5e5:6e5],np.array(pd.Series(train['signal'][5e5:6e5].rolling(1000).mean()).replace(np.nan,0)))\n",
        "print(slope,\" \",intercept)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g7Sfubr6q7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train2 = train.copy()\n",
        "a = 5e5;b1=6e5;b2=1e6\n",
        "train2.loc[a:b1,'signal'] = train2.loc[a:b1,'signal'] - ((np.ceil(slope*10)/10)*(train2.loc[a:b1,'time']) - 15)\n",
        "plt.figure(figsize=(19,5))\n",
        "plt.plot(train2.loc[a:b2,'signal'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcE0nUZI5aMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(19,5))\n",
        "plt.title(\"Signals with Drift in Batch 2\",color='white',size=20)\n",
        "plt.plot(train['signal'][::1000])\n",
        "for i in range(10):\n",
        "  plt.plot([i*5e5,i*5e5],[-4,12],'r')\n",
        "\n",
        "plt.figure(figsize=(19,5))\n",
        "plt.title(\"Signals without Drift in Batch 2\",color='white',size=20)\n",
        "plt.plot(train2['signal'][::1000])\n",
        "for i in range(10):\n",
        "  plt.plot([i*5e5,i*5e5],[-4,12],'r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIn7esT0D17l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train[train['batch'] == 6]['signal'][::100].rolling(1000).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZm_jtzEzeUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_c = pd.read_csv('train_clean.csv')\n",
        "train_c = get_batch(train_c)\n",
        "train_c.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHvVAGHCy-5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(train[train['batch'] == 6]['signal'],label='not cleaned')\n",
        "sns.distplot(train_c[train_c['batch'] == 6]['signal'],label='cleaned')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNk7Lcm9_rCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "for i in [0,3,4,5,6]:\n",
        "  sns.distplot(train[train['batch'] == i]['signal'][::1000],label=f'batch {i}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qowCoCb-xWxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(train_c['signal'],label='cleaned')\n",
        "sns.distplot(train['signal'],label='not cleaned')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeDXbVAUwHwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['drift_dis'] = train['signal'] - train_c['signal']\n",
        "plt.plot(train_c['signal'][::10000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfVdNC8QwHta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(50,5))\n",
        "sns.scatterplot(train.index,train['open_channels'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp5TdDb_PQOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train_clean.csv')\n",
        "test = pd.read_csv('test_clean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDRKvnffPQL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = get_batch(train)\n",
        "test = get_batch(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLgi479APQJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vals_gauss = signal.gausspulse(np.array(train[train['batch'] == 3]['signal'][::100]))\n",
        "vals_org = train[train['batch'] == 3]['signal'][::100].values\n",
        "vals_chnls = train[train['batch'] == 3]['open_channels'][::100].values\n",
        "plt.plot(vals_org,label='org data')\n",
        "plt.plot(vals_gauss,label='gausspulse')\n",
        "plt.plot(vals_chnls,label='channels')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoQLkDM6eWfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vals = np.array(train['signal']) * 0.3\n",
        "plt.plot(train['signal'],'o',label='current')\n",
        "plt.plot(vals,'^',label='volatge')\n",
        "plt.plot(train['open_channels'],label='channels')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg4lmtXJeWdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train['signal'],label='signal')\n",
        "plt.plot(train['open_channels'],label='channels')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyjAg52veWaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train['signal'],'+',label='signal')\n",
        "plt.plot(train['open_channels'],'.',label='channels')\n",
        "plt.xticks(np.linspace(0,5e6,21))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH9GE1GceWYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train['signal'][::1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZSiuSDoPQGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.sqrt(((4*1.308*10e-23)*230*10*10e3/10e9))\n",
        "train['c'] = a/train['signal']\n",
        "plt.plot(train['c'],label='noise')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHlQFN2HjrY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(11):\n",
        "  print(i,\" => \",train[train['batch'] == i]['signal'].mean(),train[train['batch'] == i]['signal'].std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqv44gu_jrKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train[train['batch'] == 3]['signal'][::100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N58GPan8dLU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=7\n",
        "plt.scatter(np.roll(train[train['batch'] == i]['signal'],-1),train[train['batch'] == i]['signal'],s=0.01,label=f'signal {i}')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "print(train[train['batch'] == i]['open_channels'].value_counts(normalize=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTAahx9qitu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train[train['batch'] == 7]['signal'],label='signal')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtpsvANiwsYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smooth(x,window_len=11,window='hanning'):\n",
        "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
        "    #print(len(s))\n",
        "    if window == 'flat': #moving average\n",
        "        w=np.ones(window_len,'d')\n",
        "    else:\n",
        "        w=eval('np.'+window+'(window_len)')\n",
        "\n",
        "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnQHUbkG2tGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = train.signal.shift(-1) - train.signal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqNsPARZ9rgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0.19*np.sqrt(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WanZvJgX9bzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['signal'][:10]\n",
        "a[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V6n1BeN0z5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.where(train['signal']<0,train['signal'] + 0.19,train['signal'] - 0.19)\n",
        "plt.plot(train.signal)\n",
        "plt.figure(figsize=(19,5))\n",
        "plt.plot(a[::1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klXdC5ybwsVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train['signal'][:500].rolling(50).mean(),label='original')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bowH3FpUGSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAGGokggUGKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwW365uZDxvK",
        "colab_type": "text"
      },
      "source": [
        "#### For Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIXRxNwdpaoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test2 = test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCNrShjE5aHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "let = ['A','B','C','D','E','F','G','H','I','J']\n",
        "r = test.signal.rolling(30000).mean()\n",
        "plt.plot(test.time.values,r)\n",
        "for i in range(21): plt.plot([500+i*10,500+i*10],[-3,6],'r:')\n",
        "for i in range(5): plt.plot([500+i*50,500+i*50],[-3,6],'r')\n",
        "for k in range(4): plt.text(525+k*50,5.5,str(k+1),size=20)\n",
        "for k in range(10): plt.text(505+k*10,4,let[k],size=16)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uBhZbAro1dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 0;b=100000\n",
        "slope, intercept, _, _, _ = stats.linregress(test.loc[test.index[a:b],'time'], test2.signal.values[a:b])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcm74wUzqXTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test2.loc[a:b,'signal'] = test2.loc[a:b,'signal'] - (np.round(slope,2)*test2.loc[a:b,'time']) + intercept\n",
        "plt.plot(test2['signal'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7iLbF6-5aDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(test['signal'].rolling(1000).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5IQsFig5Z_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP0mR1kx5Z8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ufX4Ec5Z5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRKmlDxA5Z2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps729ULt5Zxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi9XLZIJ5ZuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV415Oaq5ZrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnttMv35ZoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5xX6Fevknl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CcOJIIckni6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV0WuiN2kng6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZjY8MLzkncT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqqwRF0aknZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc8ThinRknXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPjH7JeTknTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf58fo1kknSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqnledmPB4tv",
        "colab_type": "text"
      },
      "source": [
        "# Garbage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nai5cjVJLveF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\"\"\"def get_group_channel_agg(train,test):\n",
        "  groups = train.group.unique().tolist()\n",
        "  groups.sort()\n",
        "  group_max = {}\n",
        "  group_min = {}\n",
        "  group_mean = {}\n",
        "  group_std = {}\n",
        "  group_var = {}\n",
        "  for i in tqdm_notebook(groups):\n",
        "    group_mean[i] = {}\n",
        "    group_mean[i].update(train[train['group'] == i].groupby('open_channels')['signal'].mean().to_dict())\n",
        "\n",
        "    group_max[i] = {}\n",
        "    group_max[i].update(train[train['group'] == i].groupby('open_channels')['signal'].max().to_dict())\n",
        "\n",
        "    group_min[i] = {}\n",
        "    group_min[i].update(train[train['group'] == i].groupby('open_channels')['signal'].min().to_dict())\n",
        "\n",
        "    group_std[i] = {}\n",
        "    group_std[i].update(train[train['group'] == i].groupby('open_channels')['signal'].std().to_dict())\n",
        "\n",
        "    group_var[i] = {}\n",
        "    group_var[i].update(train[train['group'] == i].groupby('open_channels')['signal'].var().to_dict())\n",
        "\n",
        "  for df in tqdm_notebook([train,test]):\n",
        "    for x in groups:\n",
        "      df[f'group_{x}_channel_sig_mean'] = df['group'].map(group_mean[x])\n",
        "      df[f'group_{x}_channel_sig_max'] = df['group'].map(group_max[x])\n",
        "      df[f'group_{x}_channel_sig_min'] = df['group'].map(group_min[x])\n",
        "      df[f'group_{x}_channel_sig_std'] = df['group'].map(group_std[x])\n",
        "      df[f'group_{x}_channel_sig_var'] = df['group'].map(group_mean[x])\n",
        "\n",
        "  return train, test\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Whw7T4R-foD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\"\"\"for x in tqdm_notebook(train.columns[6:57]):\n",
        "  train[f'{x}_msignal'] = train[x] - train['signal']\n",
        "\n",
        "for x in tqdm_notebook(train.columns[6:57]):\n",
        "  test[f'{x}_msignal'] = test[x] - test['signal']\n",
        "\n",
        "for x in tqdm_notebook(train.columns[57:108]):\n",
        "  train[f'{x}_msignal'] = train[x] - train['signal']\n",
        "\n",
        "for x in tqdm_notebook(train.columns[57:108]):\n",
        "  test[f'{x}_msignal'] = test[x] - test['signal']\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoiqMIRQbK-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(df):\n",
        "    df['rolling_signal_mean'] = df['signal'].rolling(10,min_periods=1).mean()\n",
        "    df['rolling_signal_median'] = df['signal'].rolling(10,min_periods=1).median()\n",
        "\n",
        "    for x in tqdm_notebook(['batch','batch_slices2']):\n",
        "      sig_mean = df.groupby(x)['signal'].mean().to_dict()\n",
        "      sig_median = df.groupby(x)['signal'].median().to_dict()\n",
        "      sig_std = df.groupby(x)['signal'].std().to_dict()\n",
        "      sig_max = df.groupby(x)['signal'].max().to_dict()\n",
        "      sig_min = df.groupby(x)['signal'].min().to_dict()\n",
        "      sig_mean_abs_diff = df.groupby(x)['signal'].apply(lambda x: np.mean(np.absolute(np.diff(x)))).to_dict()\n",
        "      sig_mean_non_abs_diff = df.groupby(x)['signal'].apply(lambda x:np.mean(np.diff(x))).to_dict()\n",
        "      sig_skew = df.groupby(x)['signal'].skew().to_dict()\n",
        "      sig_kurt = df.groupby(x)['signal'].apply(pd.DataFrame.kurt).to_dict()\n",
        "      sig_kurt_zscore = {x:y[0] for (x,y) in df.groupby(x)['signal'].apply(stats.kurtosistest).to_dict().items()}\n",
        "      sig_kurt_pvalue = {x:y[0] for (x,y) in df.groupby(x)['signal'].apply(stats.kurtosistest).to_dict().items()}\n",
        "      sig_sem = df.groupby(x)['signal'].apply(stats.sem).to_dict()\n",
        "      sig_skew_zscore = {x:y[0] for (x,y) in df.groupby(x)['signal'].apply(stats.skewtest).to_dict().items()}\n",
        "      sig_skew_pvalue = {x:y[1] for (x,y) in df.groupby(x)['signal'].apply(stats.skewtest).to_dict().items()}\n",
        "      sig_zscore_mean = {x:np.mean(y) for (x,y) in df.groupby(x)['signal'].apply(stats.zscore).to_dict().items()}\n",
        "      sig_zscore_max = {x:np.max(y) for (x,y) in df.groupby(x)['signal'].apply(stats.zscore).to_dict().items()}\n",
        "      sig_zscore_min = {x:np.min(y) for (x,y) in df.groupby(x)['signal'].apply(stats.zscore).to_dict().items()}\n",
        "      sig_zscore_std = {x:np.std(y) for (x,y) in df.groupby(x)['signal'].apply(stats.zscore).to_dict().items()}\n",
        "      sig_zscore_var = {x:np.var(y) for (x,y) in df.groupby(x)['signal'].apply(stats.zscore).to_dict().items()}\n",
        "      sig_zscore_median = {x:np.median(y) for (x,y) in df.groupby(x)['signal'].apply(stats.zscore).to_dict().items()}\n",
        "      sig_relfreq_freq_mean = {x:np.mean(y[0]) for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_freq_median = {x:np.mean(y[0]) for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_freq_max = {x:np.mean(y[0]) for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_freq_min = {x:np.mean(y[0]) for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_freq_std = {x:np.mean(y[0]) for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_freq_var = {x:np.mean(y[0]) for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_lower_limit = {x:y[1] for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "      sig_relfreq_binsize = {x:y[2] for (x,y) in df.groupby(x)['signal'].apply(stats.relfreq).to_dict().items()}\n",
        "\n",
        "      sig_variance = df.groupby(x)['signal'].var().to_dict()\n",
        "\n",
        "      if x is not 'batch':\n",
        "        sig_mad = df.groupby(x)['signal'].apply(mean_abs_dev).to_dict()\n",
        "        sig_sum = df.groupby(x)['signal'].sum().to_dict()\n",
        "        df[f'{x}_sig_mad'] = df[x].map(sig_mad)\n",
        "        df[f'{x}_sig_sum'] = df[x].map(sig_sum)\n",
        "\n",
        "      df[f'{x}_sig_mean'] =  df[x].map(sig_mean)\n",
        "      df[f'{x}_sig_median'] =  df[x].map(sig_median)\n",
        "      df[f'{x}_sig_std'] = df[x].map(sig_std)\n",
        "      df[f'{x}_sig_max'] =  df[x].map(sig_max)\n",
        "      df[f'{x}_sig_min'] =  df[x].map(sig_min)\n",
        "      df[f'{x}_sig_abs_max'] = 0 - df[f'{x}_sig_min']\n",
        "      df[f'{x}_sig_abs_min'] = 0 - df[f'{x}_sig_max']\n",
        "      df[f'{x}_sig_mean_abs_diff'] = df[x].map(sig_mean_abs_diff)\n",
        "      df[f'{x}_sig_mean_non_abs_diff'] = df[x].map(sig_mean_non_abs_diff)\n",
        "      df[f'{x}_range'] = df[f'{x}_sig_max'] - df[f'{x}_sig_min']\n",
        "      df[f'{x}_max_by_min'] = df[f'{x}_sig_max'] / df[f'{x}_sig_min']\n",
        "      df[f'{x}_abs_min_max_avg'] = (df[f'{x}_sig_abs_max'] + df[f'{x}_sig_abs_min'])/2.0\n",
        "      df[f'{x}_min_max_avg'] = (df[f'{x}_sig_max'] + df[f'{x}_sig_min'])/2.0\n",
        "      df[f'{x}_sig_shift_pos'] = df.groupby(x)['signal'].shift()\n",
        "      df[f'{x}_sig_shift_neg'] = df.groupby(x)['signal'].shift(-1)\n",
        "      df[f'{x}_max_to_abs_min_diff'] = df[f'{x}_sig_max'] - np.absolute(df[f'{x}_sig_min'])\n",
        "      df[f'{x}_sig_kurtosis'] = df[x].map(sig_kurt)\n",
        "      df[f'{x}_sig_skew'] = df[x].map(sig_skew)\n",
        "      df[f'{x}_sig_kurt_zscore'] = df[x].map(sig_kurt_zscore)\n",
        "      df[f'{x}_sig_kurt_pvalue'] = df[x].map(sig_kurt_pvalue)\n",
        "      df[f'{x}_sig_skew_zscore'] = df[x].map(sig_skew_zscore)\n",
        "      df[f'{x}_sig_skew_pvalue'] = df[x].map(sig_skew_pvalue)\n",
        "      df[f'{x}_sig_sem'] = df[x].map(sig_sem)\n",
        "      df[f'{x}_sig_zscore_mean'] = df[x].map(sig_zscore_mean)\n",
        "      df[f'{x}_sig_zscore_min'] = df[x].map(sig_zscore_min)\n",
        "      df[f'{x}_sig_zscore_max'] = df[x].map(sig_zscore_max)\n",
        "      df[f'{x}_sig_zscore_median'] = df[x].map(sig_zscore_median)\n",
        "      df[f'{x}_sig_zscore_std'] = df[x].map(sig_zscore_std)\n",
        "      df[f'{x}_sig_zscore_var'] = df[x].map(sig_zscore_var)\n",
        "      df[f'{x}_sig_relfreq_freq_mean'] = df[x].map(sig_relfreq_freq_mean)\n",
        "      df[f'{x}_sig_relfreq_freq_min'] = df[x].map(sig_relfreq_freq_min)\n",
        "      df[f'{x}_sig_relfreq_freq_max'] = df[x].map(sig_relfreq_freq_max)\n",
        "      df[f'{x}_sig_relfreq_freq_std'] = df[x].map(sig_relfreq_freq_std)\n",
        "      df[f'{x}_sig_relfreq_freq_median'] = df[x].map(sig_relfreq_freq_median)\n",
        "      df[f'{x}_sig_relfreq_freq_var'] = df[x].map(sig_relfreq_freq_var)\n",
        "      df[f'{x}sig_relfreq_lower_limit'] = df[x].map(sig_relfreq_lower_limit)\n",
        "      df[f'{x}_sig_relfreq_binsize'] = df[x].map(sig_relfreq_binsize)\n",
        "\n",
        "      \n",
        "      if x is not 'batch':\n",
        "        df[f'{x}_abs_min_range_from_mean'] = df[f'{x}_sig_abs_min'] - df[f'{x}_sig_mean']\n",
        "        df[f'{x}_abs_max_range_from_mean'] = df[f'{x}_sig_abs_max'] - df[f'{x}_sig_mean']\n",
        "        df[f'{x}_abs_min_range_from_mad'] = df[f'{x}_sig_abs_min'] - df[f'{x}_sig_mad']\n",
        "        df[f'{x}_abs_max_range_from_mad'] = df[f'{x}_sig_abs_max'] - df[f'{x}_sig_mad']\n",
        "\n",
        "\n",
        "    df['signal_rolling_10_sum'] = df['signal'].rolling(10,min_periods=1).sum()\n",
        "    df['signal_rolling_10_mean'] = df['signal'].rolling(10,min_periods=1).mean()\n",
        "    df['signal_shift_pos'] = df['signal'].shift()\n",
        "    df['signal_shift_neg'] = df['signal'].shift(-1)\n",
        "\n",
        "    for c in [c for c in df.columns if c not in ['time','signal','open_channels','batch_index','batch','batch_slices2','batch_slices']]:\n",
        "      df[f'{c}_msignal'] = df[c] - df['signal']\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}